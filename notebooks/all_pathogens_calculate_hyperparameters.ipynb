{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c35a28d-5d85-47b0-8f0f-b0f65f427147",
   "metadata": {},
   "source": [
    "# Calculate model hyperameters for all pathogens\n",
    "Uses the [Dask ML](https://ml.dask.org/) implementations of [GridSearchCV](https://ml.dask.org/modules/generated/dask_ml.model_selection.GridSearchCV.html) and [RandomizedSearchCV](https://ml.dask.org/modules/generated/dask_ml.model_selection.RandomizedSearchCV.html) to find hyperparameters for ML models.\n",
    "\n",
    "The codes executed on the [University of Florida's HiPerGator supercomputer](https://www.rc.ufl.edu/about/hipergator/). The resource allocations were:\n",
    "* 2 A100 GPUs\n",
    "* 32 CPU cores\n",
    "* 64 GB of memory\n",
    "\n",
    "When possible, GridSearchCV was used. However, this was not feasible for all models. The search algorithm for each model was:\n",
    "* GridSearchCV\n",
    "  * Logistic Regression\n",
    "  * Support Vector Classifier\n",
    "* RandomizedSearchCV\n",
    "  * Random Forest Classifer\n",
    "  * XGBoost Classifier\n",
    "  * Multilayer Perceptron\n",
    "  \n",
    "Note: The `miRNA-analysis` kernel was used to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "563b0b02-8a98-4581-9dac-6b0cf241b3f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trying to supress sklearn warning\n",
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore::UserWarning\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9602f3cc-9afd-4bf1-b07d-dd09d8a91f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_ml.model_selection as dcv\n",
    "import sklearn\n",
    "\n",
    "# metrics \n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# utils\n",
    "from util import make_mirna_nanostring_df, make_study_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebbcd7b-5dd9-40a8-b9eb-9939406f4b87",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f961dc-8bd6-40da-bfa9-d64102da8905",
   "metadata": {},
   "source": [
    "Use `dask_ml` library for hyperparamerter optimatization (HPO).  \n",
    "Refs:\n",
    "- https://docs.rapids.ai/deployment/stable/examples/xgboost-randomforest-gpu-hpo-dask/notebook/#randomsearch\n",
    "- https://ml.dask.org/modules/generated/dask_ml.model_selection.GridSearchCV.html\n",
    "- https://ml.dask.org/modules/generated/dask_ml.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb3b164-4101-4bac-9f00-484da97f9f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_wrapper(y, y_hat, score_function: f1_score):\n",
    "    \"\"\"\n",
    "    A wrapper function to convert labels to float32,\n",
    "    and pass it to score_function.\n",
    "\n",
    "    Params:\n",
    "    - y: The y labels that need to be converted\n",
    "    - y_hat: The predictions made by the model\n",
    "    \"\"\"\n",
    "    y = y.astype(\"float32\")  # cuML RandomForest needs the y labels to be float32\n",
    "    return score_function(y, y_hat, convert_dtype=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bcdf02b-b239-4b82-8778-cc552bdfa7e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exec_HPO(model, gridsearch_params, X, y, scorer=f1_score, n_folds=5, mode=\"gpu-random\", n_iter=25, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform HPO based on the mode specified\n",
    "\n",
    "    mode: default gpu-Grid. The possible options are:\n",
    "    1. gpu-grid: Perform GPU based GridSearchCV\n",
    "    2. gpu-random: Perform GPU based RandomizedSearchCV\n",
    "\n",
    "    n_iter: specified with Random option for number of parameter settings sampled\n",
    "\n",
    "    Returns the best estimator and the results of the search\n",
    "    \"\"\"\n",
    "    \n",
    "    if mode == \"gpu-grid\":\n",
    "        print(\"gpu-grid selected\")\n",
    "        clf = dcv.GridSearchCV(\n",
    "            model, gridsearch_params, cv=n_folds, scoring=make_scorer(scorer)\n",
    "        )\n",
    "    elif mode == \"gpu-random\":\n",
    "        print(\"gpu-random selected\")\n",
    "        clf = dcv.RandomizedSearchCV(\n",
    "            model, gridsearch_params, cv=n_folds, scoring=make_scorer(scorer), n_iter=n_iter, random_state=random_state\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(\"Unknown Option, please choose one of [gpu-grid, gpu-random]\")\n",
    "        return None, None\n",
    "    res = clf.fit(X, y)\n",
    "    print(f\"Best clf:\\n {res.best_estimator_} \\nscore ({scorer.__name__}):\\n{res.best_score_}\\n---\\n\")\n",
    "    return res.best_params_\n",
    "    # return res.best_estimator_, res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0fe87-8150-43f0-ba23-68b557eafd0a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59ae4c-6a27-4c57-afda-32b868bd4afd",
   "metadata": {},
   "source": [
    "## load miRNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3d9b30c-707f-417b-a3fd-5faefa1fd38d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('../data/Fusobacterium_nucleatum/8 weeks F. nucleatum infection.csv',\n",
       "  'inf_fn_8_weeks'),\n",
       " ('../data/Fusobacterium_nucleatum/8 weeks SHAM infection.csv',\n",
       "  'sham_fn_8_weeks'),\n",
       " ('../data/Fusobacterium_nucleatum/16 weeks F. nucleatum infection.csv',\n",
       "  'inf_fn_16_weeks'),\n",
       " ('../data/Fusobacterium_nucleatum/16 weeks SHAM infection.csv',\n",
       "  'sham_fn_16_weeks'),\n",
       " ('../data/Porphyromonas_gingivalis/8 weeks P. gingivalis NanoString Data.csv',\n",
       "  'inf_pg_8_weeks'),\n",
       " ('../data/Porphyromonas_gingivalis/8 weeks SHAM RAW data.csv',\n",
       "  'sham_pg_8_weeks'),\n",
       " ('../data/Porphyromonas_gingivalis/16 weeks P. gingivalis  NanoString Data.csv',\n",
       "  'inf_pg_16_weeks'),\n",
       " ('../data/Porphyromonas_gingivalis/16 weeks SHAM RAW data.csv',\n",
       "  'sham_pg_16_weeks'),\n",
       " ('../data/Streptococcus_gordonii/8 weeks S.gordonii infection.csv',\n",
       "  'inf_sg_8_weeks'),\n",
       " ('../data/Streptococcus_gordonii/8 weeks SHAM infection.csv',\n",
       "  'sham_sg_8_weeks'),\n",
       " ('../data/Streptococcus_gordonii/16 weeks S. gordonii infection.csv',\n",
       "  'inf_sg_16_weeks'),\n",
       " ('../data/Streptococcus_gordonii/16 weeks SHAM infection.csv',\n",
       "  'sham_sg_16_weeks'),\n",
       " ('../data/Tannerella_forsythia/8 weeks T. forsythia bacteria infected mice RAW data.csv',\n",
       "  'inf_tf_8_weeks'),\n",
       " ('../data/Tannerella_forsythia/8 weeks SHAM RAW data.csv', 'sham_tf_8_weeks'),\n",
       " ('../data/Tannerella_forsythia/16 weeks T. forsythia bacteria infected mice RAW data.csv',\n",
       "  'inf_tf_16_weeks'),\n",
       " ('../data/Tannerella_forsythia/16 weeks SHAM RAW data.csv',\n",
       "  'sham_tf_16_weeks'),\n",
       " ('../data/Treponema_denticola/8 weeks T. denticola bacteria infected mice RAW data.csv',\n",
       "  'inf_td_8_weeks'),\n",
       " ('../data/Treponema_denticola/8 weeks SHAM RAW data.csv', 'sham_td_8_weeks'),\n",
       " ('../data/Treponema_denticola/16 weeks T. denticola bacteria infected mice RAW data.csv',\n",
       "  'inf_td_16_weeks'),\n",
       " ('../data/Treponema_denticola/16 weeks SHAM RAW data.csv',\n",
       "  'sham_td_16_weeks')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = [\n",
    "    '../data/Fusobacterium_nucleatum/8 weeks F. nucleatum infection.csv',\n",
    "    '../data/Fusobacterium_nucleatum/8 weeks SHAM infection.csv',\n",
    "    '../data/Fusobacterium_nucleatum/16 weeks F. nucleatum infection.csv',\n",
    "    '../data/Fusobacterium_nucleatum/16 weeks SHAM infection.csv',\n",
    "    '../data/Porphyromonas_gingivalis/8 weeks P. gingivalis NanoString Data.csv',\n",
    "    '../data/Porphyromonas_gingivalis/8 weeks SHAM RAW data.csv',\n",
    "    '../data/Porphyromonas_gingivalis/16 weeks P. gingivalis  NanoString Data.csv',\n",
    "    '../data/Porphyromonas_gingivalis/16 weeks SHAM RAW data.csv',\n",
    "    '../data/Streptococcus_gordonii/8 weeks S.gordonii infection.csv',\n",
    "    '../data/Streptococcus_gordonii/8 weeks SHAM infection.csv',\n",
    "    '../data/Streptococcus_gordonii/16 weeks S. gordonii infection.csv',\n",
    "    '../data/Streptococcus_gordonii/16 weeks SHAM infection.csv',\n",
    "    '../data/Tannerella_forsythia/8 weeks T. forsythia bacteria infected mice RAW data.csv',\n",
    "    '../data/Tannerella_forsythia/8 weeks SHAM RAW data.csv',\n",
    "    '../data/Tannerella_forsythia/16 weeks T. forsythia bacteria infected mice RAW data.csv',\n",
    "    '../data/Tannerella_forsythia/16 weeks SHAM RAW data.csv',\n",
    "    '../data/Treponema_denticola/8 weeks T. denticola bacteria infected mice RAW data.csv',\n",
    "    '../data/Treponema_denticola/8 weeks SHAM RAW data.csv',\n",
    "    '../data/Treponema_denticola/16 weeks T. denticola bacteria infected mice RAW data.csv',\n",
    "    '../data/Treponema_denticola/16 weeks SHAM RAW data.csv'\n",
    "]\n",
    "cohort_names = [\n",
    "    'inf_fn_8_weeks', 'sham_fn_8_weeks', 'inf_fn_16_weeks', 'sham_fn_16_weeks',\n",
    "    'inf_pg_8_weeks', 'sham_pg_8_weeks', 'inf_pg_16_weeks', 'sham_pg_16_weeks',\n",
    "    'inf_sg_8_weeks', 'sham_sg_8_weeks', 'inf_sg_16_weeks', 'sham_sg_16_weeks',\n",
    "    'inf_tf_8_weeks', 'sham_tf_8_weeks', 'inf_tf_16_weeks', 'sham_tf_16_weeks',\n",
    "    'inf_td_8_weeks', 'sham_td_8_weeks', 'inf_td_16_weeks', 'sham_td_16_weeks'\n",
    "]\n",
    "list(zip(file_names, cohort_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11567c1e-dc03-4ba4-8485-b3d31bee364a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 604)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miRNA_df = make_mirna_nanostring_df(file_names, cohort_names)\n",
    "miRNA_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f413f3-0440-4203-969e-1bc89ac5b8e5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e308e1-0e20-4f9e-a1e3-9c328418a14a",
   "metadata": {},
   "source": [
    "## create cohort dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17532bf0-78d9-4d1d-a5dc-5d923b2fd1c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T04:55:34.975574Z",
     "start_time": "2023-11-05T04:55:34.900339Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_8_weeks = make_study_df(miRNA_df, cohort_str='8_weeks', infected_str='inf_')\n",
    "df_16_weeks = make_study_df(miRNA_df, cohort_str='16_weeks', infected_str='inf_')\n",
    "df_all_weeks = make_study_df(miRNA_df, infected_str='inf_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284187d9-9792-4917-bef0-ef2f6ae4ae41",
   "metadata": {},
   "source": [
    "### create X, y datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a0cb406-df1b-4d2b-acf3-99d6e3ab961f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_8_weeks, y_8_weeks = df_8_weeks.drop('infected', axis=1), df_8_weeks['infected']\n",
    "X_16_weeks, y_16_weeks = df_16_weeks.drop('infected', axis=1), df_16_weeks['infected']\n",
    "X_all_weeks, y_all_weeks = df_all_weeks.drop('infected', axis=1), df_all_weeks['infected']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0ae2b1-17ee-40d1-822a-a8817e17d354",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e573b5a-0781-4b8e-bbb4-7e4da91b253b",
   "metadata": {},
   "source": [
    "## random forest - search for best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ffdd603-0d7c-474d-9612-7f25d28b357d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# see https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "# n_estimators: Number of trees in random forest\n",
    "# max_features: Number of features to consider at every split\n",
    "# max_depth: Maximum number of levels in tree\n",
    "# min_samples_split: Minimum number of samples required to split a node\n",
    "# min_samples_leaf: Minimum number of samples required at each leaf node\n",
    "# bootstrap: Method of selecting samples for training each tree\n",
    "# oob_score: (bool) Whether to use out-of-bag samples to estimate the generalization score\n",
    "param_grid = {\n",
    "    'criterion' :['gini', 'entropy'],\n",
    "    'n_estimators': list(range(10, 301, 10)), # [10, 20, 30, ... 300]\n",
    "    'max_features': ['sqrt','log2', None],\n",
    "    'max_depth': list(range(10, 201, 10)) + [None],# [10, 20, 30, ... 200, None]\n",
    "    'min_samples_split': list(range(2, 11, 2)), # [2, 4, 6, ... 10]\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'random_state': list(range(0, 9, 10)) # [0, 3, 6, 9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32305def-5bde-44a2-bda2-154564a21ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # used for testing a single run\n",
    "# print('** 8 weeks params **')\n",
    "# print(f\"\"\"Best params:\\n\n",
    "#     {exec_HPO(RandomForestClassifier(), param_grid, X_8_weeks, y_8_weeks)}\\n\"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5c61eed-65fc-4fee-adb4-cf8565a514cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** 8 weeks params **\n",
      "gpu-random selected\n",
      "Best clf:\n",
      " RandomForestClassifier(max_depth=130, max_features='log2', min_samples_leaf=2,\n",
      "                       min_samples_split=4, n_estimators=210, random_state=0) \n",
      "score (f1_score):\n",
      "0.9894736842105263\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'random_state': 0, 'n_estimators': 210, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 130, 'criterion': 'gini'}\n",
      "\n",
      "** 16 weeks params **\n",
      "gpu-random selected\n",
      "Best clf:\n",
      " RandomForestClassifier(max_depth=130, max_features='log2', min_samples_leaf=2,\n",
      "                       min_samples_split=4, n_estimators=210, random_state=0) \n",
      "score (f1_score):\n",
      "0.9789473684210526\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'random_state': 0, 'n_estimators': 210, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 130, 'criterion': 'gini'}\n",
      "\n",
      "** All weeks params **\n",
      "gpu-random selected\n",
      "Best clf:\n",
      " RandomForestClassifier(criterion='entropy', max_depth=100, max_features='log2',\n",
      "                       min_samples_split=10, n_estimators=210, random_state=0) \n",
      "score (f1_score):\n",
      "0.9948717948717949\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'random_state': 0, 'n_estimators': 210, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 100, 'criterion': 'entropy'}\n",
      "\n",
      "CPU times: user 2min 29s, sys: 2.99 s, total: 2min 32s\n",
      "Wall time: 58.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('** 8 weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(RandomForestClassifier(), param_grid, X_8_weeks, y_8_weeks)}\\n\"\"\"\n",
    ")\n",
    "\n",
    "print('** 16 weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(RandomForestClassifier(), param_grid, X_16_weeks, y_16_weeks)}\\n\"\"\"\n",
    ")\n",
    "\n",
    "print('** All weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(RandomForestClassifier(), param_grid, X_all_weeks, y_all_weeks)}\\n\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd9a5ba-aa9f-44b9-859c-1acc7e12f0ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1604d440-7134-4944-9feb-d6aa2a67a04c",
   "metadata": {},
   "source": [
    "## xgboost - search for best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "783cea38-ddbb-4fe0-84ea-d918e46bcfc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# see https://medium.com/grabngoinfo/hyperparameter-tuning-for-xgboost-91449869c57e\n",
    "# see https://medium.com/@rithpansanga/the-main-parameters-in-xgboost-and-their-effects-on-model-performance-4f9833cac7c\n",
    "# n_estimators: Number of trees in random forest\n",
    "# max_depth: Maximum number of levels in tree\n",
    "# tree_method: Tree construction algorithm used in XGBoost\n",
    "# colsample_bytree: Percentage of columns to be randomly samples for each tree.\n",
    "# eta: Learning rate\n",
    "# gamma: Minimum loss reduction required to make further partition\n",
    "# reg_alpha provides l1 regularization to the weight, higher values result in more conservative models\n",
    "# reg_lambda provides l2 regularization to the weight, higher values result in more conservative models\n",
    "\n",
    "param_grid = {\n",
    "    \"objective\": [\"binary:logistic\"],\n",
    "    \"n_estimators\": list(range(25, 1001, 25)), # [25, 50, 75, ... 1000],\n",
    "    \"booster\": [\"gbtree\"], # note TreeExplainer only supports gbtree\n",
    "    \"learning_rate\": [0.1, 0.3, 0.5, 0.7, 0.9, 1],\n",
    "    \"gamma\": [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'max_depth': list(range(10, 201, 10)) + [None],# [10, 20, 30, ... 200, None],\n",
    "    \"colsample_bytree\": [i/10.0 for i in range(3,10)],\n",
    "    # \"reg_alpha\": [1e-5, 1e-2, 0.1, 1, 10, 100], # not searching\n",
    "    # \"reg_lambda\": [1e-5, 1e-2, 0.1, 1, 10, 100], # not seqarching\n",
    "    'random_state': list(range(0, 9, 10)) # [0, 3, 6, 9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b99cac05-94b9-48c8-84f6-3ac97ce6cfa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # used for testing a single run\n",
    "# print('** 8 weeks params **')\n",
    "# print(f\"\"\"Best params:\\n\n",
    "#     {exec_HPO(xgb.XGBClassifier(), param_grid, X_8_weeks, y_8_weeks)}\\n\"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11bf9ebe-1421-4445-ae56-f1b071b87dae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** 8 weeks params **\n",
      "gpu-random selected\n",
      "Best clf:\n",
      " XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=0.3, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.9, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=150, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=0, ...) \n",
      "score (f1_score):\n",
      "0.9789473684210526\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'random_state': 0, 'objective': 'binary:logistic', 'n_estimators': 1000, 'max_depth': 150, 'learning_rate': 0.9, 'gamma': 0.3, 'colsample_bytree': 0.7, 'booster': 'gbtree'}\n",
      "\n",
      "** 16 weeks params **\n",
      "gpu-random selected\n",
      "Best clf:\n",
      " XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=0.3, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.9, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=150, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=0, ...) \n",
      "score (f1_score):\n",
      "0.967251461988304\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'random_state': 0, 'objective': 'binary:logistic', 'n_estimators': 1000, 'max_depth': 150, 'learning_rate': 0.9, 'gamma': 0.3, 'colsample_bytree': 0.7, 'booster': 'gbtree'}\n",
      "\n",
      "** All weeks params **\n",
      "gpu-random selected\n",
      "Best clf:\n",
      " XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.3, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=0.0, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=200, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=250, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=0, ...) \n",
      "score (f1_score):\n",
      "0.9948717948717949\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'random_state': 0, 'objective': 'binary:logistic', 'n_estimators': 250, 'max_depth': 200, 'learning_rate': 0.1, 'gamma': 0.0, 'colsample_bytree': 0.3, 'booster': 'gbtree'}\n",
      "\n",
      "CPU times: user 11min 16s, sys: 2min 39s, total: 13min 56s\n",
      "Wall time: 5min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('** 8 weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(xgb.XGBClassifier(), param_grid, X_8_weeks, y_8_weeks)}\\n\"\"\"\n",
    ")\n",
    "\n",
    "print('** 16 weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(xgb.XGBClassifier(), param_grid, X_16_weeks, y_16_weeks)}\\n\"\"\"\n",
    ")\n",
    "\n",
    "print('** All weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(xgb.XGBClassifier(), param_grid, X_all_weeks, y_all_weeks)}\\n\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62026e8b-af54-476e-9755-c61aff283857",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c060abec-1fdf-4a77-a427-5252ae5c5ed5",
   "metadata": {},
   "source": [
    "## logistic regression - search for best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d60f60b-5cd2-4692-9ec2-e379d1c94d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# L2 regularization, newton-cg and lbfgs only support l2\n",
    "param_grid = {\n",
    "    'penalty' : ['l2'], # 'penalty' : ['l1, 'l2'] - use only l2\n",
    "    'C': [0.1, 1, 10, 100, 1000], \n",
    "    'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'max_iter': [50, 100, 150, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0311d0fe-73bb-490b-aa95-eecc90d27dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # used for testing a single run\n",
    "# print('** 8 weeks params **')\n",
    "# print(f\"\"\"Best params:\\n\n",
    "#     {exec_HPO(LogisticRegression(), param_grid, X_8_weeks, y_8_weeks, mode=\"gpu-grid\")}\\n\"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9df35f44-8044-4b26-b3c4-e9d3919ea719",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** 8 weeks params **\n",
      "gpu-grid selected\n",
      "Best clf:\n",
      " LogisticRegression(C=0.1, max_iter=50, solver='newton-cg') \n",
      "score (f1_score):\n",
      "0.9578947368421052\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\n",
      "** 16 weeks params **\n",
      "gpu-grid selected\n",
      "Best clf:\n",
      " LogisticRegression(C=1) \n",
      "score (f1_score):\n",
      "0.9450292397660819\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "** All weeks params **\n",
      "gpu-grid selected\n",
      "Best clf:\n",
      " LogisticRegression(C=10, max_iter=200) \n",
      "score (f1_score):\n",
      "0.9236334078439341\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "CPU times: user 44.1 s, sys: 9.62 s, total: 53.7 s\n",
      "Wall time: 32.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('** 8 weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(LogisticRegression(), param_grid, X_8_weeks, y_8_weeks, mode=\"gpu-grid\")}\\n\"\"\"\n",
    ")\n",
    "\n",
    "print('** 16 weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(LogisticRegression(), param_grid, X_16_weeks, y_16_weeks, mode=\"gpu-grid\")}\\n\"\"\"\n",
    ")\n",
    "\n",
    "print('** All weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(LogisticRegression(), param_grid, X_all_weeks, y_all_weeks, mode=\"gpu-grid\")}\\n\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f90ace2-0d13-4721-8921-b2dda16bce9a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6057fe9f-e789-4668-acb0-30a963e2f5a6",
   "metadata": {},
   "source": [
    "## support vector machine classifer - search for best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e912368e-003f-4cc8-8611-26d92ead4ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1,1, 10, 100, 1000], \n",
    "    'gamma': ['scale', 1,0.1,0.01,0.001, 0.0001],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dced3e51-73d3-4ef4-b240-80e610108ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # used for testing a single run\n",
    "# print('** 8 weeks params **')\n",
    "# print(f\"\"\"Best params:\\n\n",
    "#     {exec_HPO(SVC(), param_grid, X_8_weeks, y_8_weeks, mode=\"gpu-grid\")}\\n\"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7260a3c0-8928-43db-bd28-d9ef639580c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** 8 weeks params **\n",
      "gpu-grid selected\n",
      "Best clf:\n",
      " SVC(C=1, gamma=1) \n",
      "score (f1_score):\n",
      "1.0\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      "** 16 weeks params **\n",
      "gpu-grid selected\n",
      "Best clf:\n",
      " SVC(C=1, gamma=1) \n",
      "score (f1_score):\n",
      "1.0\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      "** All weeks params **\n",
      "gpu-grid selected\n",
      "Best clf:\n",
      " SVC(C=1, gamma=1) \n",
      "score (f1_score):\n",
      "1.0\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      "CPU times: user 17.9 s, sys: 385 ms, total: 18.2 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('** 8 weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(SVC(), param_grid, X_8_weeks, y_8_weeks, mode=\"gpu-grid\")}\\n\"\"\"\n",
    ")\n",
    "\n",
    "print('** 16 weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(SVC(), param_grid, X_16_weeks, y_16_weeks, mode=\"gpu-grid\")}\\n\"\"\"\n",
    ")\n",
    "\n",
    "print('** All weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(SVC(), param_grid, X_all_weeks, y_all_weeks, mode=\"gpu-grid\")}\\n\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f7e5b-8822-4191-808f-24b6f6ba9cf9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84476ec-05ef-4f16-9427-6e618e159538",
   "metadata": {},
   "source": [
    "## multilayer perceptron - search for best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "525f57ff-8061-46ad-8837-ca2bd8ae74c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# see https://panjeh.medium.com/scikit-learn-hyperparameter-optimization-for-mlpclassifier-4d670413042b\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(256, 128), (300, 150), (400, 200)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha': [0.01, 0.001, 0.0001, 0.05],\n",
    "    'learning_rate': ['constant', 'adaptive', 'invscaling']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2446a18-9b13-4c2b-933c-a5a362066344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # used for testing a single run\n",
    "# print('** 8 weeks params **')\n",
    "# print(f\"\"\"Best params:\\n\n",
    "#     {exec_HPO(MLPClassifier(), param_grid, X_8_weeks, y_8_weeks)}\\n\"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "406bda86-617a-4565-94d2-dcbf070769fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** 8 weeks params **\n",
      "gpu-random selected\n",
      "Best clf:\n",
      " MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=(400, 200),\n",
      "              solver='lbfgs') \n",
      "score (f1_score):\n",
      "0.9684210526315788\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'solver': 'lbfgs', 'learning_rate': 'constant', 'hidden_layer_sizes': (400, 200), 'alpha': 0.01, 'activation': 'tanh'}\n",
      "\n",
      "** 16 weeks params **\n",
      "gpu-random selected\n",
      "Best clf:\n",
      " MLPClassifier(activation='tanh', hidden_layer_sizes=(300, 150),\n",
      "              learning_rate='adaptive', solver='lbfgs') \n",
      "score (f1_score):\n",
      "0.9567251461988303\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'solver': 'lbfgs', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (300, 150), 'alpha': 0.0001, 'activation': 'tanh'}\n",
      "\n",
      "** All weeks params **\n",
      "gpu-random selected\n",
      "Best clf:\n",
      " MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=(300, 150),\n",
      "              solver='lbfgs') \n",
      "score (f1_score):\n",
      "0.8999010346378767\n",
      "---\n",
      "\n",
      "Best params:\n",
      "\n",
      "    {'solver': 'lbfgs', 'learning_rate': 'constant', 'hidden_layer_sizes': (300, 150), 'alpha': 0.01, 'activation': 'tanh'}\n",
      "\n",
      "CPU times: user 2d 22h 36min 27s, sys: 31.4 s, total: 2d 22h 36min 58s\n",
      "Wall time: 2h 16min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('** 8 weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(MLPClassifier(), param_grid, X_8_weeks, y_8_weeks)}\\n\"\"\"\n",
    ")\n",
    "\n",
    "print('** 16 weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(MLPClassifier(), param_grid, X_16_weeks, y_16_weeks)}\\n\"\"\"\n",
    ")\n",
    "\n",
    "print('** All weeks params **')\n",
    "print(f\"\"\"Best params:\\n\n",
    "    {exec_HPO(MLPClassifier(), param_grid, X_all_weeks, y_all_weeks)}\\n\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbabb300-87af-41ad-9675-7c95808f28aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miRNA-analysis",
   "language": "python",
   "name": "mirna-analyis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
